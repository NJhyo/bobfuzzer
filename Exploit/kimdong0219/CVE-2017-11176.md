# CVE-2017-11176: A step-by-step Linux Kernel exploitation (part 1/4)


## Lab Setup


시작은 저번 `vnik`과 같이 `smep smap kaslr` 보호기법을 모두 꺼야한다.<br>

```c
# /etc/default/grub
GRUB_CMDLINE_LINUX_DEFAULT="quiet nokaslr nosmap"
GRUB_CMDLINE_LINUX="initrd=/install/initrd.gz"
```
<br>

Debian은 `SLAB`구조를 기본으로 사용한다 반면에 Ubuntu는 `SLUB`으로 되어있다.<br>
SLAB구조로 되어있는지 확인해 보자.<br>

```c
$ grep "CONFIG_SL.B=" /boot/config-$(uname -r)
CONFIG_SLAB=y
```
`CONFIG_SLAB=y`으로 되어있지 않다면, 커널을 다시 컴파일해야 한다.<br>

`systemtap`을 설치하면 kernel 버전 업그레이드가 되므로 다음 package를 받자.<br>

```c
# wget https://snapshot.debian.org/archive/debian-security/20160904T172241Z/pool/updates/main/l/linux/linux-image-3.16.0-4-amd64_3.16.36-1%2Bdeb8u1_amd64.deb
# wget https://snapshot.debian.org/archive/debian-security/20160904T172241Z/pool/updates/main/l/linux/linux-image-3.16.0-4-amd64-dbg_3.16.36-1%2Bdeb8u1_amd64.deb
# wget https://snapshot.debian.org/archive/debian-security/20160904T172241Z/pool/updates/main/l/linux/linux-headers-3.16.0-4-amd64_3.16.36-1%2Bdeb8u1_amd64.deb

# dpkg -i linux-image-3.16.0-4-amd64_3.16.36-1+deb8u1_amd64.deb
# dpkg -i linux-image-3.16.0-4-amd64-dbg_3.16.36-1+deb8u1_amd64.deb
# dpkg -i linux-headers-3.16.0-4-amd64_3.16.36-1+deb8u1_amd64.deb
```


`systemtap`을 설치해보자.<br>

```c
# apt install systemtap
```

설치를 하고 아래 명령어로 확인해보자.<br>

```c
# stap -v -e 'probe vfs.read {printf("read performed\n"); exit()}'
stap: Symbol `SSL_ImplementedCiphers' has different size in shared object, consider re-linking
Pass 1: parsed user script and 106 library script(s) using 87832virt/32844res/5328shr/28100data kb, in 100usr/10sys/118real ms.
Pass 2: analyzed script: 1 probe(s), 1 function(s), 3 embed(s), 0 global(s) using 202656virt/149172res/6864shr/142924data kb, in 1180usr/730sys/3789real ms.
Pass 3: translated to C into "/tmp/stapWdpIWC/stap_1390f4a5f16155a0227289d1fa3d97a4_1464_src.c" using 202656virt/149364res/7056shr/142924data kb, in 0usr/20sys/23real ms.
Pass 4: compiled C into "stap_1390f4a5f16155a0227289d1fa3d97a4_1464.ko" in 6310usr/890sys/13392real ms.
Pass 5: starting run.
read performed
Pass 5: run completed in 10usr/20sys/309real ms
```

<br>

또한 target kernel은 compile하고 exploit을 돌려야 하므로 다음을 설치하자.<br>

```c
# apt install binutils gcc
$ wget https://raw.githubusercontent.com/lexfo/linux/master/cve-2017-11176.c
```
<br>

설치후에 제시된 타겟과 논문의 타겟의 코드 차이점으로 `kmalloc-1024` 대신 `kmalloc-2048`로 하자.<br>

```c
#define KMALLOC_TARGET 2048
```

이제 compile을 해서 exploit을 해보자.<br>

```c
# gcc -fpic -O0 -std=c99 -Wall -pthread cve-2017-11176.c -o exploit
# ./exploit
[ ] -={ CVE-2017-11176 Exploit }=-
[+] successfully migrated to CPU#0
[+] userland structures allocated:
[+] g_uland_wq_elt = 0x120001000
[+] g_fake_stack   = 0x20001000
[+] ROP-chain ready
[ ] optmem_max = 20480
[+] can use the 'ancillary data buffer' reallocation gadget!
[+] g_uland_wq_elt.func = 0xffffffff8107b6b8
[+] reallocation data initialized!
[ ] initializing reallocation threads, please wait...
[+] 200 reallocation threads ready!
[+] reallocation ready!
[+] 300 candidates created
[+] parsing '/proc/net/netlink' complete
[+] adjacent candidates found!
[+] netlink candidates ready:
[+] target.pid = -4166
[+] guard.pid  = -4304
[ ] preparing blocking netlink socket
[+] receive buffer reduced
[ ] flooding socket
[+] flood completed
[+] blocking socket ready
[+] netlink fd duplicated (unblock_fd=403, sock_fd2=404)
[ ] creating unblock thread...
[+] unblocking thread has been created!
[ ] get ready to block
[ ][unblock] closing 438 fd
[ ][unblock] unblocking now
[+] mq_notify succeed
[ ] creating unblock thread...
[+] unblocking thread has been created!
[ ] get ready to block
[ ][unblock] closing 404 fd
[ ][unblock] unblocking now
[+] mq_notify succeed
[+] guard socket closed
[ ] addr_len = 12
[ ] addr.nl_pid = -4166
[ ] magic_pid = 296082670
[-] magic PID does not match!
[-] failed to check realloc success status!
[-] reallocation failed!
[-] exploit failed!
[ ] press key to continue...

```
<br>

다음과 같이 exploit을 실패하게 된다.<br>

이 타겟을 위해 만들어진것이 아니기 때문이다.<br>

따라서 part 3 과 part4에서 수정을 할것이다.<br>

**target 과 제시된 상황의 차이점으로 kernel crashes를 받지 않을것이다.**<br>

그이유로는 커널은 자동적으로 특정 에러에 크래쉬하지 않지만 간단히 hang이 되거나 `kill exploit`이 되기도 한다.<br>

하지만, 불안정한 상태이고 언제든지 크래쉬가 발생할수 있다.<br>

코드를 읽어보고 그런 차이점들을 이해하는 것을 추천한다.<br>

----

## Getting Kernel Source Code

```c
wget https://snapshot.debian.org/archive/debian-security/20160904T172241Z/pool/updates/main/l/linux/linux-source-3.16_3.16.36-1%2Bdeb8u1_all.deb

dpkg -i linux-source-3.16_3.16.36-1+deb8u1_all.deb
```
<br>

커널 source code는 `/usr/src/linux-source-3.16.tar.xz`에 있다.<br>

target 커널은 크래쉬가 많이 발생하기 때문에 커널 코드를 분석하고 host system에서 exploit을 작성하자.<br>

그래서 이 소스들을 host system으로 가져오자.<br>

타겟은 compile과 run하고 systemtap사용시에만 사용하도록 한다.<br>

## Core Concepts

커널의 가장 중요한 구조체 중 하나는 `struct task_struct`이다.<br>

모든 task는 task_struct를 memory에 가지고 있다.<br>

`userland process`는 적어도 하나의 task로 이루어져 있다.<br>

`multi-threaded application`에서도 모든 thread에 대해 하나의 task_strcut를 가지고 있다.<br>

커널 thread들은 각자의 `task_struct`를 가지고 있다. ex) kworker, migration<br>

```c
// [include/linux/sched.h]

struct task_struct {
    volatile long state;            // process state (running, stopped, ...)
    void *stack;                    // task's stack pointer
    int prio;                       // process priority
    struct mm_struct *mm;           // memory address space
    struct files_struct *files;     // open file information
    const struct cred *cred;        // credentials
  // ...
};
```
<br>

## File Descriptor, File Object and File Descriptor Table

리눅스 커널에서 7종류의 파일들이 있다.<br>

`regular,directory, link, character device, block device, fifo, socket`<br>

각 파일들은 file descriptor에 의해 명시된다. <br>

`file descriptor`는 기본적으로 주어진 프로세스에 대해서만 의미가 있는 정수이다.<br>

각 file descriptor에는 stuct file이 존재한다.<br>

`struct file`은 열려있는 파일을 명시한다.<br>

이것은 disk의 image에 매칭이 필요가 없다.<br>

예를 들어, /proc같은 파일시스템 경로에 접근 할때, 시스템은 cursor를 track해야 한다.<br>

이러한 종류의 정보들은 `struct file`에 저장된다.<br>

`struct file`에서 가장 중요한 필드는 다음과 같다.<br>

```c
// [include/linux/fs.h]

struct file {
    loff_t                            f_pos;            // "cursor" while reading file
    atomic_long_t                     f_count;          // object's reference counter
    const struct file_operations      *f_op;            // virtual function table (VFT) pointer
  void                              *private_data;      // used by file "specialization"
  // ...
};
```
<br>

`file descriptor`를 struct file pointer에 mapping시키는 것을 `file descriptor table(FDT)`이라 부른다.<br>

이것은 1:1 mapping이 아니고 몇가지의 `file descriptor`가 같은 file object에 pointed 될수 있다.<br>

이 경우에 pointed fileobject는 `reference counter`가 있다.<br>

`FDT`는 struct fdtable이라 불리는 struct에 저장된다.

이것은 단지 `file descripot`로 색인할수 있는 `struct file pointer`의 배열일 뿐이다.<br>

```c
// [include/linux/fdtable.h]

struct fdtable {
    unsigned int max_fds;
    struct file ** fd;      /* current fd array */
  // ...
};
```

`FDT`를 process에 링크 시키는 것은 struct `files_struct`이다.<br>

`fdtable`이 `task_struct`에 직접 들어있지 않은 이유는 다른 정보를 가지고 있기 때문이다.<br>

`file_struct`는 몇가지의 threads에 의해 공유 될수 있고 몇가지의 최적화 기술들이 있다.<br>

```c
// [include/linux/fdtable.h]

struct files_struct {
    atomic_t count;           // reference counter
    struct fdtable *fdt;      // pointer to the file descriptor table
  // ...
};
```
<br>

`file_struct` 포인터는 task_struct에 저장되어 있다.<br>

## Virtual Functon Table (VFT)

대부분 C로 개발되었지만 Linux는 객체지향 Kernel을 가지고있다.<br>

일반성을 달성하기 위해 vft를 사용한다.<br>

vft는 대부분이 함수 포인터로 구성되어있다.<br>

```c
// [include/linux/fs.h]

struct file_operations {
    ssize_t (*read) (struct file *, char __user *, size_t, loff_t *);
    ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);
    int (*open) (struct inode *, struct file *);
    int (*release) (struct inode *, struct file *);
  // ...
};
```
<br>

모든 것들이 파일이지만 같이 형태가 아닌것 처럼 `file operation(f_ops)`도 다 다르다.<br>

이것이 `kernel code`가 파일의 타입과 코드 인수와는 별개로 파일을 처리할 수 있다.<br>

```c
if (file->f_op->read)
ret = file->f_op->read(file, buf, count, pos);
```
<br>

## Socket, Sock and SKB

`struct socket`은 network stack의 최상위에 있다. <br>

소켓이 생성이 되는동안, 새로운 `struct file`이 생성되고 그것의 `file operation`은 `socket_file_ops`에 생성 된다.<br>

모든 파일이 `file descriptor`에 의해 명시 되므로 우리는 `file descriptor`를 read,write,close등으로 지정하는 명령어를 사용할수 있다.<br>

소켓의 타입과 개별적으로, 커널은 `generic socket file operation`를 호출한다.<br>

```c
// [net/socket.c]

static const struct file_operations socket_file_ops = {
    .read = sock_aio_read,      // <---- calls sock->ops->recvmsg()
    .write =    sock_aio_write, // <---- calls sock->ops->sendmsg()
    .llseek =   no_llseek,      // <---- returns an error
  // ...
}
```
<br>

`struct socket`은 BSD socket API(connect, bind, accept, listen)등을 구현 하기 때문에, `struct proto_ops`라는 특별한 vft를 추가 하였다.<br>

모든 타입의 소켓은 자체 `proto_ops`를 구현한다.<br>

```c
// [include/linux/net.h]

struct proto_ops {
    int     (*bind)    (struct socket *sock, struct sockaddr *myaddr, int sockaddr_len);
    int     (*connect) (struct socket *sock, struct sockaddr *vaddr,  int sockaddr_len, int flags);
    int     (*accept)  (struct socket *sock, struct socket *newsock, int flags);
  // ...
}
```
<br>

BSD 스타일의 syscall이 호출 될때 (ex: bind()) 커널은 일반적으로 그 체계를 따른다.<br>

1. `file descriptor table`에서 을 검색한다.<br>
2. `struct file`에서 `struct socket`을 검색한다.<br>
3. 특수한 `proto_ops` callback을 호출한다.<br>

몇몇의 `protocol operation`은 `network stack`의 낮은 계층으로 가야하고, `struct socket`은 `struct sock object`로의 포인터가 있다.<br>

이 포인터는 `socket protocol operations(proto_ops)`에 의해 쓰인다.<br>

끝으로 `struct socket`은 `struct file`과 `struct sock`사이의 연결점 같은 역할을 한다.<br>

```c
// [include/linux/net.h]

struct socket {
    struct file     *file;
    struct sock     *sk;
    const struct proto_ops  *ops;
  // ...
};
```
<br>
`struct sock`은 복잡한 데이터 구조체이다.<br>

`network card driver`와 `socket`사이의 중간쯤으로 볼수 있다.<br>

주요목적은 buffer를 송수신 하는 것이다.<br>

packet이 network card를 통해 받아졌을때, 드라이버는 패킷을 `sock receive buffer`에 `enqueued`한다.<br>

이것은 프로그램이 recvmsg() syscall을 하기 전까지 저장되어있다.<br>

반대로 프로그램이 sendmsg() syscall을 하기 전까지 저장되어있다.<br>

정해지면, network card는 `dequeue`를 하고 packet을 전송한다.<br>

이러한 `network packets`은 `struct sk_buff`라고 불린다.<br>

```c
// [include/linux/sock.h]

struct sock {
    int         sk_rcvbuf;    // theorical "max" size of the receive buffer
    int         sk_sndbuf;    // theorical "max" size of the send buffer
    atomic_t        sk_rmem_alloc;  // "current" size of the receive buffer
    atomic_t        sk_wmem_alloc;  // "current" size of the send buffer
    struct sk_buff_head sk_receive_queue;   // head of doubly-linked list
    struct sk_buff_head sk_write_queue;     // head of doubly-linked list
    struct socket       *sk_socket;
  // ...
}
```
<br>

보다시피, `struct sock(sk)`과 `struct socket(sock)`은 서로를 참조한다.<br>

마찬가지로, `struct file`과 `struct socket`은 서로를 참조한다.<br>

이 `2-way mechanism`이 data를 위 아래로 이동할수 있게 해준다.<br>


## Netlink SOCKET

`Netlink socket`은 UNIX나 INET socket의 타입이다.<br>

`Netlink socket`은 kernel과 userspace 의 연결점이다.<br>

이것은 또한 `routing table`을 수정하는데 사용할수 있고, `SElinux event notification`을 받을수 있게 해준다.<br>
또한, `userland process`와도 연결이 가능하다.<br>

`struct sock`과 `struct socket`은 모든 종류의 소켓들을 지원하는 일반적인 데이터 구조체이다.<br>

소켓의 특성상 `the proto_ops` 필드는 defined가 되야한다.<br>

`netlink family`를 위한 BSD-style socket은 `netlink_ops`이다.<br>

```c
// [net/netlink/af_netlink.c]

static const struct proto_ops netlink_ops = {
   .bind =     netlink_bind,
   .accept =   sock_no_accept,     // <--- calling accept() on netlink sockets leads to EOPNOTSUPP error
   .sendmsg =  netlink_sendmsg,
   .recvmsg =  netlink_recvmsg,
 // ...
}
```
<br>

이것이 `netlink_sock`으로 만들어진다.<br>

```c
// [include/net/netlink_sock.h]

struct netlink_sock {
    /* struct sock has to be the first member of netlink_sock */
    struct sock     sk;
    u32         pid;
    u32         dst_pid;
    u32         dst_group;
  // ...
};
```
<br>

다른 말로, `netlink_sock`은 추가적인 특성이 있는 `sock`이라고 할수있다.<br>

----

## Putting it all together

`core data structure`가 소개되었으니 하나에 모아서 시각화를 시켜보겠다.<br>

![enter image description here](https://github.com/Kimdong0219/image/blob/master/%EC%A3%BC%EC%84%9D%202019-10-09%20203016.png?raw=true)
<br>

**각 화살표들은 포인터를 명시한다.**<br>
**`sock structure`는 `netlink_sock structure`안에 있다.**<br>

## Reference counters

커널 주요 개념의 소개를 마치려면 커널이 `ref counter`를 처리하는 방법을 이해해야 한다.<br>

커널에서 `memory leak`을 줄이고 `use-after-free`를 방어하기 위해 대부분의 리눅스 데이터 구조는 `ref counter`를 가지 있다.<br>

`ref counter`는 자체적으로 기본 인수형인 `atomic_t` type으로 명시되어있다.<br>

 `ref counter`는 `atomic operations`통해서만 작동된다.<br>

 * `atomic_inc()`
 * `atomic_add()`
 * `atomic_dec_and_test()`

 `smart pointer`가 없기때문에, `ref counter`를 개발자가 수작업으로 해야한다.<br>

이 작업은 참조할때는 증가시키고 참조를 안할때는 감소시켜야 한다는 것이다.<br>

결과적으로 `ref counter`가 0이될때 `free`되는 것이다.<br>

**하지만, 불균형이 있을 경우 메모리 손상의 위험이 있다.**<br>

* refcounter decreased twice: use-after-free<br>

* refcounter increased twice: memory leak or int-overflow on the refcounter leading to use-after-free<br>

리눅스 커널에는 `refcounter`를 처리할수 있는 여러 기능이 있다.<br>
